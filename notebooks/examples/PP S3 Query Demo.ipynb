{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PP S3 Query Demo\n",
    "* StellarAlgo Data Science\n",
    "* Peter Morrison\n",
    "* June 27, 2022\n",
    "\n",
    "This notebook demonstrates 3 ways to query S3\n",
    "\n",
    "To read these from Legacy environment you will need to asssume the Explore-US role. See an example of assuming the Legacy role here https://github.com/stellaralgo/data-sci-retention/blob/main/lambdas/inference/post_process_scores/post_process_scores.py#L43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "\n",
    "from pycaret.clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAM_ROLE = \"\"\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        \"name\": \"galaxy\"\n",
    "    },\n",
    "]\n",
    "\n",
    "date = datetime.date.today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This lets you assume the Explore-US Role\n",
    "\n",
    "role_arn = \"\" # will need to add role_arn for Explore-US\n",
    "\n",
    "client_sts = boto3.client(\"sts\")\n",
    "\n",
    "sts_response = client_sts.assume_role(\n",
    "    RoleArn=role_arn,\n",
    "    RoleSessionName=\"ds_session\",\n",
    ")\n",
    "\n",
    "ds_session_id = sts_response[\"Credentials\"][\"AccessKeyId\"]\n",
    "ds_session_key = sts_response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "ds_session_token = sts_response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "boto3.setup_default_session(\n",
    "    region_name=\"us-east-1\",\n",
    "    aws_access_key_id=ds_session_id,\n",
    "    aws_secret_access_key=ds_session_key,\n",
    "    aws_session_token=ds_session_token,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Querying the S3 Bucket to get a Dataframe of the Scores\n",
    "Pros\n",
    "* Allows you to manipulate data before writing to Redshift\n",
    "\n",
    "Cons\n",
    "* Have to handle querying the folder structure by date and team name\n",
    "* Have to handle and maintain the list of team names (like if a team is added)\n",
    "* Poor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for config in configs:\n",
    "    url = f\"s3://explore-us-curated-data-sci-product-propensity-us-east-1-u8gldf/product-propensity-scores/date={date}/{config['name']}.parquet\"\n",
    "\n",
    "    df = pd.read_parquet(url)\n",
    "    # have to write to redshift\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Redshift Copy\n",
    "Pros\n",
    "* Writes directly to Redshift\n",
    "* Good performance\n",
    "\n",
    "Cons\n",
    "* Have to handle querying the folder structure by date and team name\n",
    "* Have to handle and maintain the list of team names (like if a team is added)\n",
    "* Can't do data manipulations before pushing to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = \"\"\n",
    "host = \"\"\n",
    "user = \"\"\n",
    "password = \"\"\n",
    "\n",
    "conn = psycopg2.connect(dbname=dbname, host=host, port='5439', user=user, password=password)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Begin your transaction\n",
    "cur.execute(\"begin;\")\n",
    "\n",
    "for config in configs:\n",
    "    s3_path = f\"s3://explore-us-curated-data-sci-product-propensity-us-east-1-u8gldf/product-propensity-scores/date={date}/{config['name']}.parquet\"\n",
    "    cur.execute(f\"copy score_data from '{s3_path}' IAM_ROLE '{IAM_ROLE}' parquet;\")\n",
    "\n",
    "\n",
    "# Commit your transaction\n",
    "cur.execute(\"commit;\")\n",
    "print(\"Copy executed fine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Athena Interface\n",
    "Pros\n",
    "* Don't have to handle querying the folder structure by date and team name\n",
    "* Don't have to handle and maintain the list of team names (like if a team is added)\n",
    "  * Both of the above are done by Athena\n",
    "* Better performance than option 1\n",
    "* Allows you to manipulate data like option 1\n",
    "\n",
    "Cons\n",
    "* Can't do data manipulations before pushing to Redshift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "client = boto3.client(\"athena\")\n",
    "\n",
    "# This will read the data\n",
    "query_start = client.start_query_execution(\n",
    "    QueryString = \"Select * FROM product_propensity_scores\",\n",
    "    QueryExecutionContext = {\n",
    "        \"Database\": \"data-sci\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# To get the status of the query:\n",
    "query_execution = client.get_query_execution(QueryExecutionId=query_start['QueryExecutionId'])\n",
    "\n",
    "# Waits until the query succeeds. Would need a FAILED and CANCELLED check.\n",
    "while query_execution.Status.State != \"SUCCEEDED\":\n",
    "    time.sleep(15)\n",
    "\n",
    "# To get the data in Lambda. Specify the MaxResults for number of rows per page.\n",
    "results = client.get_query_results(QueryExecutionId=query_start['QueryExecutionId'], MaxResults=1000000)\n",
    "\n",
    "next_token = results[\"NextToken\"]\n",
    "while next_token:\n",
    "    results = client.get_query_results(QueryExecutionId=query_start['QueryExecutionId'], MaxResults=1000000, NextToken=next_token)\n",
    "    next_token = results[\"NextToken\"]\n",
    "    # Have to write results to Redshift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('apps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d8995fe1737de4c2c05c8672033c3f0c4589a65b9d7ca0a2c13ebbb2ea74172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
