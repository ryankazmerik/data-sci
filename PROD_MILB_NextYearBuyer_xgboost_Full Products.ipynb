{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV #cross validation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to Redshift\n",
    "conn=psycopg2.connect(dbname = 'dsprod',\n",
    "                                    host = 'sagemaker.cbpdnejrkweo.us-east-1.redshift.amazonaws.com',\n",
    "                                    port = 5439,\n",
    "                                    user = 'admin',\n",
    "                                    password='QCxaxQrpijap79XX6TiX',\n",
    "                                    sslmode='require')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamproductyear_id= 56 #1,2,3,...,74,88\n",
    "# 18,19,20 no data for testing\n",
    "#ta 42\n",
    "# 3,18 null for test\n",
    "# 56 doesn't look good only 12 records for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamproductyearid</th>\n",
       "      <th>lkupclientid</th>\n",
       "      <th>clientcode</th>\n",
       "      <th>productgrouping</th>\n",
       "      <th>trainseasonyear</th>\n",
       "      <th>testseasonyear</th>\n",
       "      <th>facttestprevyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>knights</td>\n",
       "      <td>Half Season</td>\n",
       "      <td>2019</td>\n",
       "      <td>2021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teamproductyearid  lkupclientid clientcode productgrouping  \\\n",
       "0                 56            46    knights     Half Season   \n",
       "\n",
       "   trainseasonyear  testseasonyear facttestprevyear  \n",
       "0             2019            2021             None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur2 = conn.cursor()\n",
    "sample_query_1 = f'''select teamproductyearid,lkupclientid,clientcode,productgrouping,trainseasonyear,testseasonyear,facttestprevyear from ds.productyear_all r where teamproductyearid ={teamproductyear_id} ;'''\n",
    "bnew=cur2.execute(sample_query_1)\n",
    "pnew = cur2.fetchall()\n",
    "dfparam = pd.DataFrame(pnew)\n",
    "new_columns_param = ['teamproductyearid','lkupclientid','clientcode','productgrouping','trainseasonyear','testseasonyear','facttestprevyear']\n",
    "dfparam3 = pd.DataFrame(pnew,columns=new_columns_param)\n",
    "dfparam3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramindex= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "knights\n",
      "Half Season\n",
      "2019\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "client_id = dfparam3._get_value(0,'lkupclientid')\n",
    "client_code= dfparam3._get_value(0,'clientcode')\n",
    "product_grouping =dfparam3._get_value(0,'productgrouping') \n",
    "train_season_year =dfparam3._get_value(0,'trainseasonyear') \n",
    "test_season_year =dfparam3._get_value(0,'testseasonyear') \n",
    "print(client_id)\n",
    "print(client_code)\n",
    "print(product_grouping)\n",
    "print(train_season_year)\n",
    "print(test_season_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimcustomermasterid</th>\n",
       "      <th>recency</th>\n",
       "      <th>attendancePercent</th>\n",
       "      <th>totalSpent</th>\n",
       "      <th>distToVenue</th>\n",
       "      <th>source_tenure</th>\n",
       "      <th>renewedBeforeDays</th>\n",
       "      <th>missed_games_1</th>\n",
       "      <th>missed_games_2</th>\n",
       "      <th>missed_games_over_2</th>\n",
       "      <th>isnextyear_buyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323696066</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>792</td>\n",
       "      <td>2.64</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352052982</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>594</td>\n",
       "      <td>15.13</td>\n",
       "      <td>97</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353600339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>198</td>\n",
       "      <td>2.64</td>\n",
       "      <td>79</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>353639238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>198</td>\n",
       "      <td>2.64</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>353762323</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>99</td>\n",
       "      <td>18.83</td>\n",
       "      <td>265</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dimcustomermasterid  recency attendancePercent totalSpent distToVenue  \\\n",
       "0           323696066        4          0.171875        792        2.64   \n",
       "1           352052982        0          0.510417        594       15.13   \n",
       "2           353600339        0            0.6875        198        2.64   \n",
       "3           353639238        0            0.9375        198        2.64   \n",
       "4           353762323        4              0.75         99       18.83   \n",
       "\n",
       "   source_tenure  renewedBeforeDays  missed_games_1  missed_games_2  \\\n",
       "0             51                  7               0               1   \n",
       "1             97                 37               2               0   \n",
       "2             79                 26               1               2   \n",
       "3             64                 11               1               0   \n",
       "4            265                 49               0               0   \n",
       "\n",
       "   missed_games_over_2  isnextyear_buyer  \n",
       "0                    1                 0  \n",
       "1                    1                 1  \n",
       "2                    0                 1  \n",
       "3                    0                 1  \n",
       "4                    1                 1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "sample_query = f'''select r.dimcustomermasterid,recency,attendancePercent,totalSpent,distToVenue,source_tenure,renewedBeforeDays,missed_games_1,missed_games_2,missed_games_over_2,isnextyear_buyer,isnextyear_samepkg_buyer,pkgupgrade_status from ds.retentionscoring r where lkupclientid ={client_id} and productgrouping in({\"'\"+ str(product_grouping) + \"'\"}) and year<{train_season_year};'''\n",
    "b=cur.execute(sample_query)\n",
    "p = cur.fetchall()\n",
    "df = pd.DataFrame(p)\n",
    "new_columns = ['dimcustomermasterid','recency','attendancePercent','totalSpent','distToVenue','source_tenure','renewedBeforeDays','missed_games_1','missed_games_2','missed_games_over_2','isnextyear_buyer','isnextyear_samepkg_buyer','pkgupgrade_status']\n",
    "df3 = pd.DataFrame(p,columns=new_columns)\n",
    "df3.drop(['isnextyear_samepkg_buyer','pkgupgrade_status'], axis=1, inplace=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dimcustomermasterid    12\n",
       "recency                12\n",
       "attendancePercent      12\n",
       "totalSpent             12\n",
       "distToVenue            12\n",
       "source_tenure          12\n",
       "renewedBeforeDays      12\n",
       "missed_games_1         12\n",
       "missed_games_2         12\n",
       "missed_games_over_2    12\n",
       "isnextyear_buyer       12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['dimcustomermasterid']= pd.to_numeric(df3['dimcustomermasterid'])\n",
    "df3['attendancePercent']= pd.to_numeric(df3['attendancePercent'])\n",
    "df3['totalSpent']= pd.to_numeric(df3['totalSpent'])\n",
    "df3['distToVenue']= pd.to_numeric(df3['distToVenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimcustomermasterid</th>\n",
       "      <th>recency</th>\n",
       "      <th>attendancePercent</th>\n",
       "      <th>totalSpent</th>\n",
       "      <th>distToVenue</th>\n",
       "      <th>source_tenure</th>\n",
       "      <th>renewedBeforeDays</th>\n",
       "      <th>missed_games_1</th>\n",
       "      <th>missed_games_2</th>\n",
       "      <th>missed_games_over_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dimcustomermasterid, recency, attendancePercent, totalSpent, distToVenue, source_tenure, renewedBeforeDays, missed_games_1, missed_games_2, missed_games_over_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df3.drop(['isnextyear_buyer'], axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: isnextyear_buyer, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df3['isnextyear_buyer'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0fec2ab813b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= xgb.XGBClassifier(objective='binary:logistic',seed=42,gamma=0.25,lear_rate=0.1,max_depth=6,reg_lambda=20,scale_pos_weight=3,subsample=0.9,colsample_bytree=0.5)\n",
    "clf.fit(X,y,verbose=True,early_stopping_rounds=10,eval_metric='aucpr',eval_set=[(X,y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Important features\n",
    "feature_importances_df = pd.DataFrame(\n",
    "    {\"feature\": list(X.columns), \"importance\": clf.feature_importances_}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# Display\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances=feature_importances_df[['feature','importance']]\n",
    "feature_importances['productgrouping'] = product_grouping\n",
    "feature_importances=feature_importances[['feature','importance']]\n",
    "feature_importances.drop([0],axis=0,inplace=True) \n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_dict = {}\n",
    "for ind in feature_importances.index:\n",
    "     feature_importance_dict[feature_importances['feature'][ind]] = float(feature_importances['importance'][ind])\n",
    "print(feature_importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sshtunnel import SSHTunnelForwarder\n",
    "from sshtunnel import open_tunnel\n",
    "from pymongo import MongoClient\n",
    "import ssl\n",
    "import datetime\n",
    "\n",
    "connection = MongoClient('mongodb://sean:monstertruck1@52.54.218.77:28001/?authMechanism=SCRAM-SHA-1')\n",
    "# connection\n",
    "    #for x in (connection.views.views_meta_data.find_one()):\n",
    "db = connection['views']\n",
    "collection = db['views_meta_data']\n",
    "myquery = { \"_id\":client_code }\n",
    "tenant_doc = collection.find_one(myquery)\n",
    "today = datetime.datetime.now()\n",
    "if 'date_last_retention_scores' not in tenant_doc:\n",
    "    tenant_doc['date_last_retention_scores'] = {}\n",
    "tenant_doc['date_last_retention_scores']= today        \n",
    "collection.update_one(myquery, { '$set': tenant_doc },upsert=True)\n",
    "    \n",
    "if 'attributes_std' not in tenant_doc:\n",
    "    tenant_doc['attributes_std'] = {}\n",
    "tenant_doc['attributes_std'][product_grouping] = feature_importance_dict        \n",
    "collection.update_one(myquery, { '$set': tenant_doc },upsert=True)\n",
    "\n",
    "\n",
    "    #newvalues = { \"$set\":{ \"attributes_std\": data_dict }  }\n",
    "#     collection.update_one(myquery, newvalues)\n",
    "    #collection.insert([{\"_id\":\"coyotestest\"}, {\"attributes_std\": data_dict}])\n",
    "\n",
    "       # print(x)\n",
    "#connection.close()\n",
    "#tunnel.close()\n",
    "   # tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "cur = conn.cursor()\n",
    "sample_query2 = f'''select r.dimcustomermasterid,recency,attendancePercent,totalSpent,distToVenue,source_tenure,renewedBeforeDays,missed_games_1,missed_games_2,missed_games_over_2,isnextyear_buyer,isnextyear_samepkg_buyer,pkgupgrade_status from ds.retentionscoring r where lkupclientid ={client_id} and productgrouping in({\"'\"+ str(product_grouping) + \"'\"}) and year={test_season_year};'''\n",
    "b2=cur.execute(sample_query2)\n",
    "p2 = cur.fetchall()\n",
    "df_test2 = pd.DataFrame(p2)\n",
    "new_columns_test = ['dimcustomermasterid','recency','attendancePercent','totalSpent','distToVenue','source_tenure','renewedBeforeDays','missed_games_1','missed_games_2','missed_games_over_2','isnextyear_buyer','isnextyear_samepkg_buyer','pkgupgrade_status']\n",
    "df_test = pd.DataFrame(p2,columns=new_columns)\n",
    "df_test.drop(['isnextyear_samepkg_buyer','pkgupgrade_status'], axis=1, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['dimcustomermasterid']= pd.to_numeric(df_test['dimcustomermasterid'])\n",
    "df_test['attendancePercent']= pd.to_numeric(df_test['attendancePercent'])\n",
    "df_test['totalSpent']= pd.to_numeric(df_test['totalSpent'])\n",
    "df_test['distToVenue']= pd.to_numeric(df_test['distToVenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['isnextyear_buyer'], axis=1).copy()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "# y_pred_proba = clf.predict_proba(X_test)\n",
    "#y_pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Creating the array to convert\n",
    "array_y_pred_test = np.array(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "df_y_pred_test = pd.DataFrame(array_y_pred_test)\n",
    "df_y_pred_test.columns = ['nonbuyer','buyer']\n",
    "#df_y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = pd.concat([df_y_pred_test, X_test], axis=1, join=\"inner\")\n",
    "#result_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final_result = result_train.append(result_test, sort=False)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = result_test.drop(['nonbuyer'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test['buyer']= pd.to_numeric(result_test['buyer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "date_time = today.strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "print(date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newscors=result_test[['dimcustomermasterid','buyer']]\n",
    "newscors.columns = ['dimcustomermasterid','buyer_score']\n",
    "newscors['year'] = test_season_year\n",
    "newscors['lkupclientid'] = client_id\n",
    "newscors['productgrouping'] = product_grouping\n",
    "newscors['insertDate'] = date_time\n",
    "#newscors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "# connect to SQL Server.\n",
    "server = '34.206.73.189' \n",
    "database = 'datascience' \n",
    "username = 'nrad' \n",
    "password = '83F25619-D272-4660-98A2-93AF5CC18D59' \n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# Insert Dataframe into SQL Server:\n",
    "for index, row in newscors.iterrows():\n",
    "    cursor.execute(\"INSERT INTO ds.finalscore (dimcustomermasterid,buyer_score,year,lkupclientid,productgrouping,insertDate) values(\" + str(row.dimcustomermasterid) + \",\" + str(round(row.buyer_score,4))+ \",\"+ str(row.year) + \",\" + str(row.lkupclientid)+ \",\"+\"'\"+str(row.productgrouping)+\"'\"+ \",\" +\"'\"+str(row.insertDate)+\"'\" + \")\")\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongoscores=newscors[['dimcustomermasterid','buyer_score']]#dimcustomermasterid\n",
    "mongoscores['id_tenant']= client_code\n",
    "mongoscores['productgrouping'] = product_grouping\n",
    "mongoscores['year'] = test_season_year\n",
    "mongoscores['insertDate'] = datetime.datetime.now()\n",
    "mongoscores.columns=['customerNumber','score','id_tenant','productgrouping','year','date']\n",
    "mongoscores_dict = mongoscores.to_dict(orient='records')\n",
    "#mongoscores_dict\n",
    "#mongoscores.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importancesdict=feature_importances.to_dict(orient='records')\n",
    "feature_importancesdict\n",
    "# aa = {feature_importancesdict['feature']: feature_importancesdict['importance']}\n",
    "aa = [{sample_dict['feature']: sample_dict['importance']} for sample_dict in feature_importancesdict]\n",
    "result = {}\n",
    "for d in aa:\n",
    "    result.update(d)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "final_list = []\n",
    "for single_dict in mongoscores_dict:\n",
    "    temp_dict = {}\n",
    "    temp_dict2 = {}\n",
    "    temp_dict['customerNumber']=single_dict['customerNumber']\n",
    "    temp_dict['id_tenant']=single_dict['id_tenant']\n",
    "    temp_dict['productgrouping']=single_dict['productgrouping']\n",
    "    temp_dict['year']=single_dict['year']\n",
    "    temp_dict2 = {\n",
    "        'score': single_dict['score'], \n",
    "        'date': single_dict['date'],\n",
    "        'attribute': result\n",
    "    }\n",
    "    temp_dict['history']= temp_dict2\n",
    "    final_list.append(temp_dict)\n",
    "    \n",
    "#final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sshtunnel import SSHTunnelForwarder\n",
    "from sshtunnel import open_tunnel\n",
    "from pymongo import MongoClient\n",
    "import ssl\n",
    "import datetime\n",
    "\n",
    "connection = MongoClient('mongodb://sean:monstertruck1@52.54.218.77:28001/?authMechanism=SCRAM-SHA-1')\n",
    "# connection   \n",
    "db = connection['views']\n",
    "collection = db['scores_retention'] \n",
    "for i in final_list:\n",
    "    myquery = {\"customerNumber\": i['customerNumber'],\"id_tenant\": i['id_tenant'],\"product\":i['productgrouping'] ,\"year\":i['year'] }\n",
    "    tenant_doc = collection.find_one(myquery)\n",
    "    \n",
    "    if tenant_doc is None:\n",
    "        myquery =  {\n",
    "            \"customerNumber\": i['customerNumber'],\n",
    "            \"id_tenant\": i['id_tenant'],\n",
    "            \"product\":i['productgrouping'],\n",
    "            \"year\":i['year'],\n",
    "            \"history\": [i['history']]\n",
    "        }\n",
    "        collection.insert_one(myquery)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        tenant_doc['history'].append(i['history'])\n",
    "        collection.update_one(myquery, { '$set': tenant_doc },upsert=True)\n",
    "        \n",
    "        \n",
    "        #print(tenant_doc)\n",
    "            #print(x)\n",
    "#connection.close()\n",
    "#tunnel.close()\n",
    "   # tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances2= feature_importances\n",
    "feature_importances2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances2.at[1,'feature']='Recency'\n",
    "feature_importances2.at[2,'feature']='Attendance'\n",
    "feature_importances2.at[3,'feature']='Monetary'\n",
    "feature_importances2.at[4,'feature']='Distance to Venue'\n",
    "feature_importances2.at[5,'feature']='Tenure'\n",
    "feature_importances2.at[6,'feature']='Time to Renew'\n",
    "feature_importances2.at[7,'feature']='Missed Games Streak 1'\n",
    "feature_importances2.at[8,'feature']='Missed Games Streak 2'\n",
    "feature_importances2.at[9,'feature']='Missed Games Streak Over 2'\n",
    "feature_importances2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "date_time = today.strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "print(date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances2['attrank']={1,2,3,4,5,6,7,8,9}\n",
    "feature_importances2 ['lkupClientId'] = client_id\n",
    "feature_importances2 ['modelVersnNumber'] = 2\n",
    "feature_importances2 ['scoreDate'] = date_time\n",
    "feature_importances2 ['loadId'] = 0\n",
    "feature_importances2 ['product'] = product_grouping\n",
    "feature_importances2.columns=['attribute','indexValue','attrank','lkupClientId','modelVersnNumber','scoreDate','loadId','product']\n",
    "feature_importances2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "# connect to SQL Server.\n",
    "server = '34.206.73.189' \n",
    "database = 'datascience' \n",
    "username = 'nrad' \n",
    "password = '83F25619-D272-4660-98A2-93AF5CC18D59' \n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# Insert Dataframe into SQL Server:\n",
    "# cursor.execute(\"INSERT INTO dbo.finalscore (dimcustomermasterid,buyer_score,lkupclientid,insertDate) values(1,1,1,null)\")\n",
    "for index, row in feature_importances2.iterrows():\n",
    "    cursor.execute(\"INSERT INTO stlrMILB.dw.lkupRetentionAttributeImportance (attribute,product,indexValue,rank,lkupClientId,modelVersnNumber,scoreDate,loadId) values(\" + \"'\" +str(row.attribute)+\"'\"+\",\"+ \"'\"+str(product_grouping)+\"'\" +\",\" + str(round(row.indexValue,4)) + \",\" + str(row.attrank)+ \",\"+ str(row.lkupClientId) + \",\" + str(row.modelVersnNumber)+ \",\" + \"'\"+ str(row.scoreDate)+ \"'\"+ \",\"+ str(row.loadId)  + \")\")\n",
    "     #print(\"INSERT INTO stlrMLS.dw.lkupRetentionAttributeImportance (attribute,product,indexValue,rank,lkupClientId,modelVersnNumber,scoreDate,loadId) values(\" + \"'\" +str(row.attribute)+\"'\"+\",\"+ \"'\"+str(product_grouping)+\"'\" +\",\" + str(round(row.indexValue,4)) + \",\" + str(row.attrank)+ \",\"+ str(row.lkupClientId) + \",\" + str(row.modelVersnNumber)+ \",\" + \"'\"+ str(row.scoreDate)+ \"'\"+ \",\"+ str(row.loadId)  + \")\")\n",
    "    #cursor.execute(\"INSERT INTO stlrMLS.dw.lkupRetentionAttributeImportance (attribute,product,indexValue,rank,lkupClientId,modelVersnNumber,scoreDate,loadId) values(\" + \"'\" +str(row.attribute)+\"'\"+\",\"+ \"'\"+str(product_grouping)+\"'\" +\",\" + str(round(row.indexValue,4)) + \",\" + str(row.attrank)+ \",\"+ str(row.lkupClientId) + \",\" + str(row.modelVersnNumber)+ \",\" +str(row.scoreDate) + \",\"+ str(row.loadId)  + \")\")\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
